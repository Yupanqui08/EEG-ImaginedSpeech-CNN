{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d62e2749-ad8b-4a97-bc3b-33d13e3146b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version 2 of EEG imagined speech project\n",
    "# Used https://www.kaggle.com/code/widhiwinata/grasp-and-lift-movement-detection-with-dl\n",
    "# Uses each line of data as input. Results are not above chance (About 6%)\n",
    "# Uses EEG dataset: https://zenodo.org/record/3554128#.Ye85WC-cby8 \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pywt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from glob import glob\n",
    "import scipy\n",
    "from scipy.signal import butter\n",
    "from scipy.signal import freqz\n",
    "from scipy.fftpack import fft, ifft\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5bcb43fe-0749-4fd2-ba44-e6ae90432123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_denoising(x, wavelet='db2', level=1):\n",
    "    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n",
    "    sigma = (1/0.6745) * madev(coeff[-level])\n",
    "    uthresh = sigma * np.sqrt(2 * np.log(len(x)))\n",
    "    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n",
    "    return pywt.waverec(coeff, wavelet, mode='per')\n",
    "def madev(d, axis=None):\n",
    "    \"\"\" Mean absolute deviation of a signal \"\"\"\n",
    "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e02167c8-b8c3-4121-b542-e31d8338756c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_train(file_path):\n",
    "    \"\"\" read and prepare training data \"\"\"\n",
    "    # Read data\n",
    "    data = pd.read_csv(file_path)\n",
    "    # events file\n",
    "    events_file_path = file_path.replace('_data','_events')\n",
    "    # read event file\n",
    "    labels= pd.read_csv(events_file_path)\n",
    "    clean=data.drop(['Time:256Hz' ], axis=1)#remove id\n",
    "    labels=labels.drop(['Time:256Hz' ], axis=1)#remove id\n",
    "    return  clean,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "200e2b87-8137-4350-ba83-05a8a11fbf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_test(file_path):\n",
    "    \"\"\" read and prepare training data \"\"\"\n",
    "    # Read data\n",
    "    data = pd.read_csv(file_path)\n",
    "    # events file\n",
    "    events_file_path = file_path.replace('_data','_events')\n",
    "    # read event file\n",
    "    labels= pd.read_csv(events_file_path)\n",
    "    clean=data.drop(['Time:256Hz' ], axis=1)#remove id\n",
    "    labels=labels.drop(['Time:256Hz' ], axis=1)#remove id\n",
    "    return  clean,labels\n",
    "\n",
    "def data_preprocess_train(X):\n",
    "    X_prep=scaler.fit_transform(X)\n",
    "    return X_prep\n",
    "\n",
    "def data_preprocess_test(X):\n",
    "    X_prep=scaler.transform(X)\n",
    "    return X_prep\n",
    "\n",
    "subjects = range(1,22)\n",
    "ids_tot = []\n",
    "pred_tot = []\n",
    "X_train_butter = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f80ba867-ceb3-45c6-9504-8e797b1d5142",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_raw= []\n",
    "raw = []\n",
    "y_rawt= []\n",
    "rawt = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4ee9b1ae-8b2f-40c1-83cb-e03851caac05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fixed_EEG/training_csvfiles/sub1_data_train.csv']\n",
      "['fixed_EEG/training_csvfiles/sub2_data_train.csv']\n",
      "['fixed_EEG/training_csvfiles/sub3_data_train.csv']\n",
      "['fixed_EEG/training_csvfiles/sub4_data_train.csv']\n",
      "['fixed_EEG/training_csvfiles/sub5_data_train.csv']\n",
      "['fixed_EEG/training_csvfiles/sub6_data_train.csv']\n",
      "['fixed_EEG/training_csvfiles/sub7_data_train.csv']\n",
      "['fixed_EEG/training_csvfiles/sub8_data_train.csv']\n",
      "['fixed_EEG/training_csvfiles/sub9_data_train.csv']\n",
      "['fixed_EEG/training_csvfiles/sub10_data_train.csv']\n",
      "['fixed_EEG/training_csvfiles/sub11_data_train.csv']\n",
      "['fixed_EEG/training_csvfiles/sub12_data_train.csv']\n",
      "['fixed_EEG/training_csvfiles/sub13_data_train.csv']\n",
      "['fixed_EEG/training_csvfiles/sub14_data_train.csv']\n",
      "['fixed_EEG/training_csvfiles/sub15_data_train.csv']\n",
      "['fixed_EEG/training_csvfiles/sub16_data_train.csv']\n",
      "['fixed_EEG/training_csvfiles/sub17_data_train.csv']\n",
      "['fixed_EEG/training_csvfiles/sub18_data_train.csv']\n",
      "['fixed_EEG/training_csvfiles/sub19_data_train.csv']\n",
      "['fixed_EEG/training_csvfiles/sub20_data_train.csv']\n",
      "['fixed_EEG/training_csvfiles/sub21_data_train.csv']\n"
     ]
    }
   ],
   "source": [
    "for subject in subjects:\n",
    "    \n",
    "#Read Data\n",
    "    file_paths =  sorted(glob('fixed_EEG/training_csvfiles/sub%d_data_train.csv' % (subject)))\n",
    "    print(file_paths)\n",
    "\n",
    "    for file_path in file_paths:\n",
    "      data,labels=prepare_data_train(file_path)\n",
    "      raw.append(data)\n",
    "      y_raw.append(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d544c9f2-d2c4-4a55-b5d2-117a7e550ce3",
   "metadata": {},
   "source": [
    "## Wavelet Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14aa75c6-bbb1-49ea-b18a-c7b8ca04933f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat(raw)\n",
    "y = pd.concat(y_raw)\n",
    "#transform in numpy array\n",
    "#transform train data into numpy array\n",
    "X_train =np.asarray(X.astype(float))\n",
    "y_train = np.asarray(y.astype(float))\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,Normalizer,MinMaxScaler\n",
    "scaler= StandardScaler()\n",
    "def data_preprocess_train(X):\n",
    "    X_prep=scaler.fit_transform(X)\n",
    "    return X_prep\n",
    "\n",
    "x_train_butter=wavelet_denoising(X_train)\n",
    "x_train=data_preprocess_train(x_train_butter)\n",
    "splitrate=-x_train.shape[0]//5*2\n",
    "xval=x_train[splitrate:splitrate//2]\n",
    "yval=y_train[splitrate:splitrate//2]\n",
    "xtest=x_train[splitrate//2:]\n",
    "ytest=y_train[splitrate//2:]\n",
    "xtrain=x_train[:splitrate]\n",
    "ytrain=y_train[:splitrate]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2faaef0c-5044-4bba-8f64-c0fc6ea49f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21\n",
      "21\n",
      "(2035200, 16)\n",
      "(2035200, 14)\n"
     ]
    }
   ],
   "source": [
    "print(len(raw))\n",
    "print(len(y_raw))\n",
    "print(ytrain.shape)\n",
    "print(xtrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950a945a-e2a3-4318-8e58-dc662cce1e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wavelet_denoising(x, wavelet='db2', level=3):\n",
    "    coeff = pywt.wavedec(x, wavelet, mode=\"per\")\n",
    "    sigma = (1/0.6745) * madev(coeff[-level])\n",
    "    uthresh = sigma * np.sqrt(2 * np.log(len(x)))\n",
    "    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n",
    "    return pywt.waverec(coeff, wavelet, mode='per')\n",
    "def madev(d, axis=None):\n",
    "    \"\"\" Mean absolute deviation of a signal \"\"\"\n",
    "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n",
    "\n",
    "signal=pd.read_csv('fixed_EEG/training_csvfiles/sub1_data_train.csv')\n",
    "signal = signal.drop(\"Time:256Hz\", axis=1)\n",
    "filtered = wavelet_denoising(signal, wavelet='db2', level=3)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,5))\n",
    "ax.plot(signal.iloc[:10000,1], label='signal', color=\"b\", alpha=0.5,)\n",
    "ax.plot(filtered[:10000,1], label='reconstructed signal',color=\"k\")\n",
    "ax.legend(loc='upper left')\n",
    "ax.set_title('Denoising with DWT')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b43500c-2952-4fb4-ba2c-eac39ae9b16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "ye=pd.DataFrame(y_train)\n",
    "\n",
    "ye.columns=[\"fleece \",\"goose \",\"trap \",\"thought \",\"m \",\"n \",\"ng \",\"f \", \"s \", \"sh \", \"v \", \"z \", \n",
    "            \"zh \", \"p \", \"t \", \"k \"]\n",
    "categories = list(ye.columns.values)\n",
    "sns.set(font_scale = 1)\n",
    "plt.figure(figsize=(15,8))\n",
    "ax= sns.barplot(categories, ye.iloc[:,0:].sum().values)\n",
    "plt.title(\"Number of samples labeled as active (1) out of {0} length data\".format((ye.shape[0])),fontsize=20)\n",
    "\n",
    "plt.ylabel('Number of events', fontsize=18)\n",
    "plt.xlabel('Event Type ', fontsize=12)\n",
    "#adding the text labels\n",
    "rects = ax.patches\n",
    "labels = ye.iloc[:,0:].sum().values\n",
    "\n",
    "for rect, label in zip(rects, labels):\n",
    "    height = rect.get_height()\n",
    "    ax.text(rect.get_x() + rect.get_width()/2, height + 5, label, ha='center', va='bottom', fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874c59de-f7a1-4077-86bf-e4dbd158c1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import LSTM, BatchNormalization, Conv2D, Flatten, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,roc_curve,auc\n",
    "import tensorflow as tf\n",
    "!module load gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d7b9c3-4ef0-4c7c-9db2-e999d66e8c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "!module load gpu\n",
    "load = 1\n",
    "time_steps = 1000\n",
    "subsample = 50\n",
    "model = Sequential()\n",
    "model.add(Conv2D(filters = 28, kernel_size = (7,7), padding = \"same\", activation = \"relu\", input_shape = (time_steps//subsample, 14, 1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size = (3,3)))\n",
    "model.add(Conv2D(filters = 28, kernel_size = (5,5), padding = \"same\", activation = \"relu\", input_shape = (time_steps//subsample, 14, 1)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(filters = 28, kernel_size = (3,3), padding = \"same\", activation = \"relu\", input_shape = (time_steps//subsample, 14, 1)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(14, activation = \"relu\"))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(16, activation = \"sigmoid\"))\n",
    "\n",
    "\n",
    "adam = Adam(lr = 0.0001)\n",
    "\n",
    "model.compile(optimizer = adam, loss = \"binary_crossentropy\", metrics = ['accuracy','mse'])\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6194996c-7415-499c-8d2e-89e8007772a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valgenerator():\n",
    "    while 1:\n",
    "        batch_size=14\n",
    "        x_time_data = np.zeros((batch_size, time_steps//subsample, 14))\n",
    "        yy = []\n",
    "        for i in range(batch_size):\n",
    "            random_index = np.random.randint(0, len(xval)-time_steps)\n",
    "            x_time_data[i] = xval[random_index:random_index+time_steps:subsample]\n",
    "            yy.append(yval[random_index + time_steps])\n",
    "        yy = np.asarray(yy)\n",
    "        yield x_time_data.reshape((x_time_data.shape[0],x_time_data.shape[1], x_time_data.shape[2],1)), yy\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695927ab-ce4a-4121-9570-1c90f5112efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "def generator(batch_size):\n",
    "    while 1:\n",
    "        \n",
    "        x_time_data = np.zeros((batch_size, time_steps//subsample, 14))\n",
    "        yy = []\n",
    "        for i in range(batch_size):\n",
    "            random_index = np.random.randint(0, len(xtrain)-time_steps)\n",
    "            x_time_data[i] = xtrain[random_index:random_index+time_steps:subsample]\n",
    "            yy.append(ytrain[random_index + time_steps])\n",
    "        yy = np.asarray(yy)\n",
    "        yield x_time_data.reshape((x_time_data.shape[0],x_time_data.shape[1],  x_time_data.shape[2],1)), yy\n",
    "#originally 600 steps_per_epoch, 50 epochs        \n",
    "history =model.fit_generator(generator(14), steps_per_epoch = 900, epochs = 100,validation_data=valgenerator(),\n",
    "                              validation_steps=800)\n",
    "\n",
    "print('training time taken: ',round(time.time()-start,0),'seconds')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e038a9-0140-42e7-b440-6fee79d6eca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(history):\n",
    "    acc = history.history['accuracy']\n",
    "    loss = history.history['loss']\n",
    "    val_acc = history.history['val_accuracy']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(acc))\n",
    " \n",
    "    plt.figure(figsize=(15, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, acc, 'b', label='Training acc',linewidth=2)\n",
    "    plt.plot(epochs, val_acc, 'r--', label='Validation acc',linewidth=2)\n",
    "    plt.title('Training  accuracy')\n",
    "    plt.legend()\n",
    " \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'k', label='Validationloss ')\n",
    "    plt.title('Training loss')\n",
    "    plt.legend()\n",
    " \n",
    "    plt.show()\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ebebd8-2bd8-49ed-a697-902bd4ddbae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = 1000\n",
    "subsample = 50\n",
    "def val_generator():\n",
    "    while 1:\n",
    "        batch_size = 1\n",
    "        x_time_data = np.zeros((batch_size, time_steps//subsample, 14))\n",
    "        yy = []\n",
    "        for i in range(batch_size):\n",
    "            random_index = np.random.randint(0, len(xtest)-time_steps)\n",
    "            x_time_data[i] = xtest[random_index:random_index+time_steps:subsample]\n",
    "            yy.append(ytest[random_index + time_steps])\n",
    "        yy = np.asarray(yy)\n",
    "        yield x_time_data.reshape((x_time_data.shape[0],x_time_data.shape[1], x_time_data.shape[2], 1)), yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb74d875-8e9e-43af-b86c-bce2d20cda0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_data = val_generator()\n",
    "scores = []\n",
    "num_test =5000\n",
    "for i in range(num_test):\n",
    "    x_test, y_test = next(gen_data)\n",
    "    #print(y_test)\n",
    "    while not 1 in y_test:\n",
    "        #print(x_test)\n",
    "        x_test, y_test = next(gen_data)\n",
    "    score=model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "    scores.append(score[1])\n",
    "scores = np.asarray(scores)\n",
    "\n",
    "print(\"Accuracy \", np.mean(scores))\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a4272e-631e-4ccd-9aac-bb28b4238bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Binary Relevance\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Performance metric\n",
    "from sklearn.metrics import f1_score\n",
    "lr = SGDClassifier()\n",
    "#clf = OneVsRestClassifier(LinearSVC(random_state=0))\n",
    "clf =OneVsRestClassifier(lr)\n",
    "import time\n",
    "start=time.time()\n",
    "clf.fit(xtrain,ytrain)\n",
    "\n",
    "print('training time taken: ',round(time.time()-start,0),'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995f2082-abb3-4201-a76d-cf8e5d937c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "y_score = clf.decision_function(xval)\n",
    "#y_score = clf.predict(xval)\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(6):\n",
    "    fpr[i], tpr[i], _ = roc_curve(yval[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot of a ROC curve for a specific class\n",
    "for i in range(6):\n",
    "    plt.figure()\n",
    "    plt.plot(fpr[i], tpr[i], label='ROC curve (area = %0.2f)' % roc_auc[i])\n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic example')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5408df-5680-4e1a-9f29-fd70aabdd4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn.metrics import label_ranking_average_precision_score\n",
    "predictions = clf.predict(xval)\n",
    "# accuracy\n",
    "print(\"roc_auc:\",sum(roc_auc.values())/6)\n",
    "print(\"Accuracy = \",accuracy_score(yval,predictions))\n",
    "print(\"label_ranking_average_precision_score\",label_ranking_average_precision_score(yval,predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
